#pip install BeautifulSoup                  #in case library is not installed
urllink = "https://stats.espncricinfo.com/ci/engine/stats/index.html?class=3;home_or_away=1;result=1;spanmax1=22+Dec+2020;spanmin1=30+Apr+2010;spanval1=span;template=results;type=team;view=results"
text = urlopen(urllink) # loading HTML/opening webpage from python
soup = BeautifulSoup(text,'lxml') # getting the code of HTML webpage
list_tables = soup.findAll('table',attrs = {'class':'engineTable'}) # to find all tables with class as enginetable
len(list_tables)
int_table = 0
i=0
for table in list_tables:
    caption_tag = table.findAll('caption') # for looking for caption tag inside the table with class enginetable 
    print("for table number: " + str(i+1) + ",len of caption = " + str(len(caption_tag)))
    if(len(caption_tag) == 1):
        int_table = i
    i=i+1
    
print(int_table)
data_table = list_tables[int_table]  # table which has all the data we are interested in
temp_row = tr_list[0]
td_list = temp_row.findAll('td') # to get all the columns of one row
str_cells = str(td_list[3]) # convert the HTML into string
cleantext = BeautifulSoup(str_cells, 'lxml').get_text() # remove all the tags and extract the string
td_data = []
for td in td_list:
    str_cells = str(td)
    cleantext = BeautifulSoup(str_cells, 'lxml').get_text()
    td_data.append(cleantext)
    master_data = [] # list of all matches' data
for tr in tr_list:
    td_list = tr.findAll('td') # extracted all the td inside the tr tag(for each match/row separately)
    td_data = [] # data for individual
    for td in td_list:
        str_cells = str(td)
        cleantext = BeautifulSoup(str_cells, 'lxml').get_text()
        td_data.append(cleantext)
    master_data.append(td_data) # appended entire data of a match to our master_data
    master_data = []
for j in range(1,7):
    urllink = "https://stats.espncricinfo.com/ci/engine/stats/index.html?class=3;home_or_away=1;page=" + str(j) + ";result=1;spanmax1=22+Dec+2020;spanmin1=30+Apr+2010;spanval1=span;template=results;type=team;view=results"
    text = urlopen(urllink)
    soup = BeautifulSoup(text, 'lxml')
    list_tables = soup.findAll('table', attrs = {'class':'engineTable'})
    int_table = 0
    i=0
    for table in list_tables:
        caption_tag = table.findAll('caption') # for looking for caption tag inside the table with class enginetable
        print("for table number: " + str(i+1) + ", len of caption = " + str(len(caption_tag)))
        if(len(caption_tag) == 1):
            int_table = i
        i=i+1
    data_table = list_tables[int_table]
    tr_list = data_table.findAll('tr', attrs = {'class':'data1'})
    for tr in tr_list:
        td_list = tr.findAll('td') # extracted all the td inside the tr tag(for each match/row)
        td_data = [] # data for individual
        for td in td_list:
            str_cells = str(td)
            cleantext = BeautifulSoup(str_cells, 'lxml').get_text()
            td_data.append(cleantext)
        master_data.append(td_data)
        master_data = pd.DataFrame(master_data)
        df = master_data
        df = df.drop(columns=[6,10])
        df.columns = ["Country","Result","Margin of victory","Balls remaining","Toss Result","Batting","Opponent","Venue","Date"]
        df.to_csv('C:/Users/Damle/Documents/GitHub/Python-Scrapping/homet20wins.csv')
